{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2. Deliverable Jobs (tg.common.delivery.jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSH/Docker routine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, you don't really need to do packaging or containering yourself, because we have a higher level level interfaces to do that, which is `Routine` classes. \n",
    "\n",
    "Let's create a job that we are going to package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T09:31:26.575443Z",
     "iopub.status.busy": "2022-08-09T09:31:26.564607Z",
     "iopub.status.idle": "2022-08-09T09:31:27.827688Z",
     "shell.execute_reply": "2022-08-09T09:31:27.827225Z"
    }
   },
   "outputs": [],
   "source": [
    "from tg.common.datasets.featurization import FeaturizationJob, DataframeFeaturizer\n",
    "from tg.common.datasets.selectors import Selector\n",
    "from tg.common.datasets.access import MockDfDataSource\n",
    "from tg.common import MemoryFileSyncer\n",
    "import pandas as pd\n",
    "\n",
    "mem = MemoryFileSyncer()\n",
    "\n",
    "job = FeaturizationJob(\n",
    "    name = 'job',\n",
    "    version = 'v1',\n",
    "    source = MockDfDataSource(pd.read_csv('titanic.csv')),\n",
    "    featurizers = {\n",
    "        'passengers': DataframeFeaturizer(row_selector = Selector.identity)\n",
    "    },\n",
    "    syncer = mem,\n",
    "    location = './temp/featurization_job'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, `SSHDockerJobRoutine` allows you to execute your jobs in the docker at the remote server to which you have ssh access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T09:31:27.832429Z",
     "iopub.status.busy": "2022-08-09T09:31:27.831715Z",
     "iopub.status.idle": "2022-08-09T09:31:27.846083Z",
     "shell.execute_reply": "2022-08-09T09:31:27.846382Z"
    }
   },
   "outputs": [],
   "source": [
    "from tg.common.delivery.jobs import SSHDockerJobRoutine, DockerOptions\n",
    "from tg.common.delivery.packaging import FakeContainerHandler\n",
    "\n",
    "routine = SSHDockerJobRoutine(\n",
    "    job = job,\n",
    "    remote_host_address=None,\n",
    "    remote_host_user=None,\n",
    "    handler_factory = FakeContainerHandler.Factory(),\n",
    "    options = DockerOptions(propagate_environmental_variables=[])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the fields are specified to None, because we are not going to actually start the remote job with this notebook. `remote_host_address` and `remote_host_user` arguments are self-explainatory. \n",
    "\n",
    "As for `handler_factory`, this argument must be set to one of the factories that generate `ContainerHandler`. This `ContainerHandler` class must define a remote image name and tag, and perform push operations. `ContainerHandlers` are not included to the Training Grounds core, as they usually have some company-specific code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SSHDockerJobRoutine` has methods of running your code for debugging.\n",
    "\n",
    "Using the `.attached` accesor, we can run job in the same Python process that your current code is executed. This is, of course, the fastest way to do that, and therefore it's preferrable to use this to debug for typos, wrong logic, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T09:31:27.849967Z",
     "iopub.status.busy": "2022-08-09T09:31:27.849372Z",
     "iopub.status.idle": "2022-08-09T09:31:27.948335Z",
     "shell.execute_reply": "2022-08-09T09:31:27.949961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-09 09:31:27.848467+00:00 INFO: Featurization Job job at version v1 has started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-09 09:31:27.849815+00:00 INFO: Fetching data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-09 09:31:27.909123+00:00 INFO: Data fetched, finalizing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-09 09:31:27.935127+00:00 INFO: Uploading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-09 09:31:27.941760+00:00 INFO: Featurization job completed\n"
     ]
    }
   ],
   "source": [
    "routine.attached.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.local` accessor builds package and container, then executes the container locally. This step allows debugging the following things:\n",
    "\n",
    "* If your job is serializable. This is usually achievable by not using `lambda` syntax.\n",
    "* If all the code the job uses is located inside the TG folder, and if all the references are relative. If something is wrong, you will see the import error.\n",
    "* If the environmental variables are carried to docker correctly. \n",
    "* If you have sufficient permissions to start docker\n",
    "* etc.\n",
    "\n",
    "\n",
    "This step allows you to check the deliverability of your work. As the output is quite big, we will remove it for better readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T09:31:27.956787Z",
     "iopub.status.busy": "2022-08-09T09:31:27.955924Z",
     "iopub.status.idle": "2022-08-09T09:31:41.152929Z",
     "shell.execute_reply": "2022-08-09T09:31:41.153410Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "routine.local.execute()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can retrieve logs from the container with the following useful method. Note that logs printed via `logging` are placed in stderr instead of strdout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T09:31:41.160389Z",
     "iopub.status.busy": "2022-08-09T09:31:41.159752Z",
     "iopub.status.idle": "2022-08-09T09:31:41.265921Z",
     "shell.execute_reply": "2022-08-09T09:31:41.266296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-09 09:31:40.607501+00:00 INFO: Welcome to Training Grounds. This is Job execution via Docker/SSH\n",
      "2022-08-09 09:31:40.622256+00:00 INFO: Executing job job version v1\n",
      "2022-08-09 09:31:40.622377+00:00 INFO: Featurization Job job at version v1 has started\n",
      "2022-08-09 09:31:40.622756+00:00 INFO: Fetching data\n",
      "2022-08-09 09:31:40.717595+00:00 INFO: Data fetched, finalizing\n",
      "2022-08-09 09:31:40.752158+00:00 INFO: Uploading data\n",
      "2022-08-09 09:31:40.752970+00:00 INFO: Featurization job completed\n",
      "2022-08-09 09:31:40.753167+00:00 INFO: Job completed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output, errors = routine.local.get_logs()\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`routine.remote` has the same interface as `routine.local`, and will run the container at the remote machine. The only problems you should have at these stage are permissions:\n",
    "* to push to your docker registry\n",
    "* to connect to the remote machine via SSH\n",
    "* to execute `docker run` at the remote machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "In this demo, we delivered the job to the remote server and executed it there. That concludes the featurization-related part of the Training Grounds.\n",
    "\n",
    "Note that the packaging and containering techniques are not specific for the featurization, and can process any code. In the subsequent demos, the same techniques will be applied to run the training on the remote server as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
