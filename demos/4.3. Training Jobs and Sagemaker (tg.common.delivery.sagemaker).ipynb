{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46d6b0e7",
   "metadata": {},
   "source": [
    "# 4.3. Training Jobs and Sagemaker (tg.common.delivery.sagemaker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b90763b",
   "metadata": {},
   "source": [
    "## Preparing the training task and data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83db84b5",
   "metadata": {},
   "source": [
    "Another scenario for delivery is `Sagemaker` training, that is applicable to the descendants of `TrainingTask`. We will demonstrate it with `SingleFrameTrainingTask`, as it has simpler setup, and titanic dataset. \n",
    "\n",
    "First, we need to create a dataset and place it in the right folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8764e8f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:23:35.324337Z",
     "iopub.status.busy": "2022-11-17T16:23:35.321897Z",
     "iopub.status.idle": "2022-11-17T16:23:35.986716Z",
     "shell.execute_reply": "2022-11-17T16:23:35.986327Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('titanic.csv')\n",
    "df = df.set_index('PassengerId')\n",
    "for c in ['Pclass','SibSp','Parch','Survived']:\n",
    "    df[c] = df[c].astype(float)\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "df = df[features+['Survived']]\n",
    "datasets_folder = Path('temp/datasets/titanic')\n",
    "dataset_file = datasets_folder/'titanic_project/titanic.parquet'\n",
    "os.makedirs(dataset_file.parent, exist_ok=True)\n",
    "df.to_parquet(dataset_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c37752",
   "metadata": {},
   "source": [
    "We will store it locally. We will not actually run this task on the `Sagemaker`, hence, there is no need to upload it. In real setup, you would need to upload the dataset to your `[bucket]`, respecting the following convention:\n",
    "\n",
    "* Datasets are uploaded to `[bucket]/sagemaker/[project_name]/datasets/`\n",
    "* Output of the training jobs is placed to `[bucket]/sagemaker/[project_name]/output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfefa0ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:23:35.991148Z",
     "iopub.status.busy": "2022-11-17T16:23:35.990539Z",
     "iopub.status.idle": "2022-11-17T16:23:36.354556Z",
     "shell.execute_reply": "2022-11-17T16:23:36.354991Z"
    }
   },
   "outputs": [],
   "source": [
    "from tg.common.ml import single_frame_training as sft\n",
    "from tg.common.ml import dft\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "task = sft.SingleFrameTrainingTask(\n",
    "    data_loader = sft.DataFrameLoader('Survived'),\n",
    "    model_provider=sft.ModelProvider(sft.ModelConstructor(\n",
    "            'sklearn.linear_model:LogisticRegression',\n",
    "            max_iter = 1000),\n",
    "        transformer = dft.DataFrameTransformerFactory.default_factory(),\n",
    "        keep_column_names=False),\n",
    "    evaluator=sft.Evaluation.binary_classification,\n",
    "    splitter=sft.FoldSplitter(),\n",
    "    metrics_pool = sft.MetricPool().add_sklearn(roc_auc_score)        \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de441e02",
   "metadata": {},
   "source": [
    "To start Sagemaker training even on the local machine, one needs `AWS_ROLE`. We will import it from `environment.env` file:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11230bbb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8532103a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:23:36.361704Z",
     "iopub.status.busy": "2022-11-17T16:23:36.361265Z",
     "iopub.status.idle": "2022-11-17T16:23:36.379384Z",
     "shell.execute_reply": "2022-11-17T16:23:36.378748Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tg.common import Loc\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv(Loc.root_path/'environment.env')\n",
    "'AWS_ROLE' in os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7d9026",
   "metadata": {},
   "source": [
    "Sagemaker delivery has a similar structure to the SSH/Docker: SagemakerOptions, SagemakerConfig, and three executors. As with SSH/Docker, the best way to use all this is to write a SagemakerRoutine which will set up all these.\n",
    "\n",
    "Some notes before we start:\n",
    "  * The task is not, by itself, a job, it is not self-contained, as the artefacts output is controlled by `TrainingEnvironment`. So, `SagemakerJob` is a job in the sence of `tg.common.delivery` that wraps the task and adopts its behaviour to sagemaker. Other cloud providers will probably required different tasks.\n",
    "  * Sagemaker itself reqiures some specifics in container files, so this also needs to be reflected.\n",
    "  * There are many dependencies required for training are, so we will need to change the default dependency lists.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "368fc43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f01011dd0b5f45bfbc6a3b008da5bb19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-20 17:37:25.113050 INFO: Starting stage 1/1\n",
      "2022-12-20 17:37:25.233140 INFO: Completed stage 1/1\n",
      "2022-12-20 17:37:25.236670 INFO: ###roc_auc_score_test:0.8538095238095237\n",
      "2022-12-20 17:37:25.237406 INFO: ###roc_auc_score_train:0.8600247283139194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'roc_auc_score_test': 0.8538095238095237,\n",
       " 'roc_auc_score_train': 0.8600247283139194}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tg.common.delivery.sagemaker import (SagemakerJob, SagemakerAttachedExecutor, SagemakerLocalExecutor, \n",
    "                                          DOCKERFILE_TEMPLATE, SagemakerOptions, SagemakerConfig)\n",
    "from tg.common.delivery.delivery import Packaging, Containering, DependencyList\n",
    "from yo_fluq_ds import *\n",
    "\n",
    "dependencies = FileIO.read_json('dependencies.json')\n",
    "dependencies = DependencyList('training', dependencies)\n",
    "\n",
    "\n",
    "class SagemakerRoutine:\n",
    "    def __init__(self,\n",
    "                 task,\n",
    "                 dataset: str,\n",
    "                 project_name: str,\n",
    "                 ):\n",
    "        name = type(task).__name__\n",
    "        task.info['name'] = name\n",
    "        version = '0'\n",
    "        job = SagemakerJob(task)\n",
    "        packaging = Packaging(name, version, dict(job=job))\n",
    "        packaging.dependencies = [dependencies]\n",
    "        packaging.silent = True\n",
    "\n",
    "        containering = Containering.from_packaging(packaging)\n",
    "        containering.dependencies = [dependencies]\n",
    "        containering.dockerfile_template = DOCKERFILE_TEMPLATE\n",
    "        containering.run_file_name='train.py'\n",
    "        containering.silent = True\n",
    "\n",
    "        settings = SagemakerOptions(\n",
    "            os.environ.get('AWS_ROLE'),\n",
    "            None,\n",
    "            project_name,\n",
    "            datasets_folder,\n",
    "            dataset,\n",
    "        )\n",
    "\n",
    "        self.config = SagemakerConfig(\n",
    "            job,\n",
    "            packaging,\n",
    "            containering,\n",
    "            settings\n",
    "        )\n",
    "        \n",
    "    def attached(self):\n",
    "        return SagemakerAttachedExecutor(self.config)\n",
    "        \n",
    "    def local(self):\n",
    "        return SagemakerLocalExecutor(self.config)\n",
    "    \n",
    "routine = SagemakerRoutine(task,'titanic.parquet','titanic_project')\n",
    "result = routine.attached().execute()\n",
    "result['metrics']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c1444e",
   "metadata": {},
   "source": [
    "Now we will run it in the local container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28256e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: no files found matching '*.yml' under directory 'SingleFrameTrainingTask__0'\n",
      "warning: no files found matching '*.rst' under directory 'SingleFrameTrainingTask__0'\n",
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sha256:c5e1a98741882ce94e09ce458d7ace052fbdd2517633901743fe506d457c8cfd\n",
      "Creating zuve7o5y6g-algo-1-zipal ... \n",
      "\u001b[1BAttaching to zuve7o5y6g-algo-1-zipal2mdone\u001b[0m\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:41,030 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:41,064 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:41,084 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:41,097 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m \n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m Training Env:\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m \n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m {\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m         \"training\": \"/opt/ml/input/data/training\"\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m     },\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m     \"current_host\": \"algo-1-zipal\",\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m     \"framework_module\": null,\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m         \"algo-1-zipal\"\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m     ],\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m     \"hyperparameters\": {},\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m         \"training\": {\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m         }\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m     },\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m     \"job_name\": \"singleframetrainingtask-2022-12-20-16-37-38-243\",\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m     \"master_hostname\": \"algo-1-zipal\",\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m     \"module_dir\": \"/opt/ml/code\",\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m     \"module_name\": \"train\",\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m     \"num_cpus\": 4,\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m         \"current_host\": \"algo-1-zipal\",\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m             \"algo-1-zipal\"\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m         ]\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m     },\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m     \"user_entry_point\": \"train.py\"\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m }\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m \n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m Environment variables:\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m \n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m SM_HOSTS=[\"algo-1-zipal\"]\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m SM_HPS={}\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-zipal\",\"hosts\":[\"algo-1-zipal\"]}\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m SM_INPUT_DATA_CONFIG={\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m SM_CHANNELS=[\"training\"]\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m SM_CURRENT_HOST=algo-1-zipal\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m SM_FRAMEWORK_MODULE=\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m SM_NUM_CPUS=4\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m SM_MODULE_DIR=/opt/ml/code\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-zipal\",\"framework_module\":null,\"hosts\":[\"algo-1-zipal\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"singleframetrainingtask-2022-12-20-16-37-38-243\",\"log_level\":20,\"master_hostname\":\"algo-1-zipal\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-zipal\",\"hosts\":[\"algo-1-zipal\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m SM_USER_ARGS=[]\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python37.zip:/usr/local/lib/python3.7:/usr/local/lib/python3.7/lib-dynload:/usr/local/lib/python3.7/site-packages\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m \n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m \n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m /usr/local/bin/python train.py\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m \n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m \n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:43.176351 INFO: Welcome to Training Grounds!\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:43.176506 INFO: Loading job\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:44.377714 INFO: Job of type <class 'SingleFrameTrainingTask__0.tg.common.delivery.sagemaker.job.SagemakerJob'> is loaded\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:44.377987 INFO: Job has `run` attribute\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:44.378119 INFO: This is Sagemaker Job performing a training task\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:44.378330 INFO: Preparing package properties...\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:44.378547 INFO: {\"name\": \"SingleFrameTrainingTask\", \"version\": \"0\", \"module_name\": \"SingleFrameTrainingTask__0\", \"tg_import_path\": \"SingleFrameTrainingTask__0.tg\", \"original_tg_import_path\": \"tg\", \"resources_location\": \"/usr/local/lib/python3.7/site-packages/SingleFrameTrainingTask__0/resources\"}\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:44.379271 INFO: Preparing package file...\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:44.380450 INFO: Processing hyperparameters...\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:44.380910 INFO: No hyperparameters are provided\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:44.381000 INFO: Model initialized. Jsonpickling...\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:44.383134 INFO: Starting training now...\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:44.474351 INFO: Starting stage 1/1\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:44.609980 INFO: Saved artifact /opt/ml/model/runs/0/result_df\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:44.610427 INFO: Saved artifact /opt/ml/model/runs/0/metrics\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:44.610693 INFO: Saved artifact /opt/ml/model/runs/0/info\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:44.611373 INFO: Saved artifact /opt/ml/model/runs/0/model\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:44.611785 INFO: Saved artifact /opt/ml/model/runs/0/training_task\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:44.612219 INFO: Saved artifact /opt/ml/model/runs/0/train_split\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:44.612606 INFO: Saved artifact /opt/ml/model/runs/0/test_splits\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:44.612696 INFO: Completed stage 1/1\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:44.614647 INFO: ###METRIC###roc_auc_score_test:0.8538095238095237###\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:44.614752 INFO: ###METRIC###roc_auc_score_train:0.8600247283139194###\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:44.615094 INFO: Job has exited successfully\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:44.615178 INFO: DONE. Exiting Training Grounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mzuve7o5y6g-algo-1-zipal |\u001b[0m 2022-12-20 16:37:44,919 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mzuve7o5y6g-algo-1-zipal exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "id = routine.local().execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9c8201",
   "metadata": {},
   "source": [
    "The result is stored in the local file system in the same format it would be stored in S3. This is a zipped file that contains not only the output, but also the package information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b266d045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package.tag.gz\n",
      "task.json\n",
      "package.json\n",
      "runs/\n",
      "runs/0/\n",
      "runs/0/info.pkl\n",
      "runs/0/metrics.pkl\n",
      "runs/0/model.pkl\n",
      "runs/0/result_df.parquet\n",
      "runs/0/test_splits.pkl\n",
      "runs/0/train_split.pkl\n",
      "runs/0/training_task.pkl\n"
     ]
    }
   ],
   "source": [
    "loader = routine.local().load_result(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee54f7aa",
   "metadata": {},
   "source": [
    "We can now read the dataframe with the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8bc3ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(loader.get_path('runs/0/result_df.parquet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a95660",
   "metadata": {},
   "source": [
    "We can also read pickled objects, although non-directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "075d8b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_3186/1779605262.py\", line 3, in <module>\n",
      "    FileIO.read_pickle(loader.get_path('runs/0/training_task.pkl'))\n",
      "  File \"/home/yura/anaconda3/envs/fol/lib/python3.8/site-packages/yo_fluq_ds/_misc/io.py\", line 17, in read_pickle\n",
      "    return pickle.load(file)\n",
      "ModuleNotFoundError: No module named 'SingleFrameTrainingTask__0'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "try:\n",
    "    FileIO.read_pickle(loader.get_path('runs/0/training_task.pkl'))\n",
    "except:\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75873f6a",
   "metadata": {},
   "source": [
    "This is due to the fact that the delivered training task was delivered, and the delivery process changed the module name. But the `loader` contains the method to unpickle such files regardless:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a33ecb6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:23:36.638404Z",
     "iopub.status.busy": "2022-11-17T16:23:36.637749Z",
     "iopub.status.idle": "2022-11-17T16:23:36.639994Z",
     "shell.execute_reply": "2022-11-17T16:23:36.640281Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tg.common.ml.single_frame_training.training_task.SingleFrameTrainingTask at 0x7f5f032d5d00>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.unpickle('runs/0/training_task.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9697ef",
   "metadata": {},
   "source": [
    "## Automatic task name's assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96ddf09",
   "metadata": {},
   "source": [
    "When multiple tasks are running, it's quite handy to assign to each a name that would represent the parameters of the task. Out initial idea was to implement this logic inside the task, but the downside of this approach is that parameters are many, while length of the task's name in Sagemaker is limited, and quickly reached. \n",
    "\n",
    "The alternative solution is to, first, use a factory method that builds tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "622efe53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:23:50.457908Z",
     "iopub.status.busy": "2022-11-17T16:23:50.457285Z",
     "iopub.status.idle": "2022-11-17T16:23:50.459263Z",
     "shell.execute_reply": "2022-11-17T16:23:50.458741Z"
    }
   },
   "outputs": [],
   "source": [
    "from yo_fluq_ds import Obj\n",
    "\n",
    "def build(\n",
    "    learning_rate=1, \n",
    "    network_size=[10,10], \n",
    "    context_length = 10,\n",
    "):\n",
    "    return Obj(info=dict(name=''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e2f019",
   "metadata": {},
   "source": [
    "This `build` method returns a mock for training task: we are now interested only in `info` field of the task, that will contain the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b034f7f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:23:50.464135Z",
     "iopub.status.busy": "2022-11-17T16:23:50.463475Z",
     "iopub.status.idle": "2022-11-17T16:23:50.466301Z",
     "shell.execute_reply": "2022-11-17T16:23:50.465791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'info': {'name': 'LR1-NS10'}},\n",
       " {'info': {'name': 'LR1-NS10-5'}},\n",
       " {'info': {'name': 'LR2-NS10'}},\n",
       " {'info': {'name': 'LR2-NS10-5'}}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tg.common.delivery.sagemaker import Autonamer\n",
    "\n",
    "Autonamer(build).build_tasks(learning_rate = [1, 2], network_size = [[10], [10, 5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e5fb33",
   "metadata": {},
   "source": [
    "As we can see, `Autonamer` will instantiate all the tasks and assign automatically generated names to them. Note that it does not create entry for `context_length` in the name, as it is not variable in this run. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
