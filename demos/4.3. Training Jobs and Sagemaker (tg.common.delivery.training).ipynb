{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46d6b0e7",
   "metadata": {},
   "source": [
    "# 4.3. Training Jobs and Sagemaker (tg.common.delivery.training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b90763b",
   "metadata": {},
   "source": [
    "## Preparing the training task and data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83db84b5",
   "metadata": {},
   "source": [
    "Another scenario for delivery is `Sagemaker` training, that is applicable to the descendants of `TrainingTask`. We will demonstrate it with `SingleFrameTrainingTask`, as it has simpler setup, and titanic dataset iris dataset. \n",
    "\n",
    "First, we need to create a dataset and place it in the right folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8764e8f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T11:31:53.556397Z",
     "iopub.status.busy": "2022-06-29T11:31:53.551322Z",
     "iopub.status.idle": "2022-06-29T11:31:54.299566Z",
     "shell.execute_reply": "2022-06-29T11:31:54.299887Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('titanic.csv')\n",
    "df = df.set_index('PassengerId')\n",
    "for c in ['Pclass','SibSp','Parch','Survived']:\n",
    "    df[c] = df[c].astype(float)\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "df = df[features+['Survived']]\n",
    "folder = Path('temp/datasets/titanic')\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "df.to_parquet(folder/'titanic.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c37752",
   "metadata": {},
   "source": [
    "We will store it locally. We will not actually run this task on the `Sagemaker`, hence, there is no need to upload it. In real setup, you would need to upload the dataset to your `[bucket]`, respecting the following convention:\n",
    "\n",
    "* Datasets are uploaded to `[bucket]/sagemaker/[project_name]/datasets/`\n",
    "* Output of the training jobs is placed to `[bucket]/sagemaker/[project_name]/output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfefa0ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T11:31:54.303889Z",
     "iopub.status.busy": "2022-06-29T11:31:54.303501Z",
     "iopub.status.idle": "2022-06-29T11:31:54.800732Z",
     "shell.execute_reply": "2022-06-29T11:31:54.801464Z"
    }
   },
   "outputs": [],
   "source": [
    "from tg.common.ml import single_frame_training as sft\n",
    "from tg.common.ml import dft\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "task = sft.SingleFrameTrainingTask(\n",
    "    data_loader = sft.DataFrameLoader('Survived'),\n",
    "    model_provider=sft.ModelProvider(sft.ModelConstructor(\n",
    "            'sklearn.linear_model:LogisticRegression',\n",
    "            max_iter = 1000),\n",
    "        transformer = dft.DataFrameTransformerFactory.default_factory(),\n",
    "        keep_column_names=False),\n",
    "    evaluator=sft.Evaluation.binary_classification,\n",
    "    splitter=sft.FoldSplitter(),\n",
    "    metrics_pool = sft.MetricPool().add_sklearn(roc_auc_score)        \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de441e02",
   "metadata": {},
   "source": [
    "To start Sagemaker training even on the local machine, one needs `AWS_ROLE`. We will import it from `environment.env` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8532103a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T11:31:54.806893Z",
     "iopub.status.busy": "2022-06-29T11:31:54.806041Z",
     "iopub.status.idle": "2022-06-29T11:31:54.822065Z",
     "shell.execute_reply": "2022-06-29T11:31:54.822642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tg.common import Loc\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv(Loc.root_path/'environment.env')\n",
    "'AWS_ROLE' in os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f23fb20f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T11:31:54.852790Z",
     "iopub.status.busy": "2022-06-29T11:31:54.848047Z",
     "iopub.status.idle": "2022-06-29T11:31:54.943781Z",
     "shell.execute_reply": "2022-06-29T11:31:54.943435Z"
    }
   },
   "outputs": [],
   "source": [
    "from tg.common.delivery.training import SagemakerTrainingRoutine\n",
    "from tg.common.delivery.packaging import FakeContainerHandler\n",
    "\n",
    "\n",
    "routine = SagemakerTrainingRoutine(\n",
    "    local_dataset_storage = Path('temp/datasets'),\n",
    "    project_name = 'titanic',\n",
    "    handler_factory = FakeContainerHandler.Factory(),\n",
    "    aws_role = os.environ['AWS_ROLE'],\n",
    "    s3_bucket = None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f00c6e3",
   "metadata": {},
   "source": [
    "As with `SSHDockerRoutine`, there are `attached`, `local` and `remote` accessors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106de6fe",
   "metadata": {},
   "source": [
    "## `attached` accesor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1313258",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T11:31:54.947396Z",
     "iopub.status.busy": "2022-06-29T11:31:54.947003Z",
     "iopub.status.idle": "2022-06-29T11:31:55.035096Z",
     "shell.execute_reply": "2022-06-29T11:31:55.034710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-29 11:31:54.959026+00:00 INFO: Starting stage 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-29 11:31:55.024144+00:00 INFO: Saved artifact /home/yura/Desktop/repos/tg/temp/training_results/_20220629_133154_e9070dfa1b63456abe3cce462444eec4/runs/0/result_df\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-29 11:31:55.024998+00:00 INFO: Saved artifact /home/yura/Desktop/repos/tg/temp/training_results/_20220629_133154_e9070dfa1b63456abe3cce462444eec4/runs/0/metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-29 11:31:55.025754+00:00 INFO: Saved artifact /home/yura/Desktop/repos/tg/temp/training_results/_20220629_133154_e9070dfa1b63456abe3cce462444eec4/runs/0/info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-29 11:31:55.026717+00:00 INFO: Saved artifact /home/yura/Desktop/repos/tg/temp/training_results/_20220629_133154_e9070dfa1b63456abe3cce462444eec4/runs/0/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-29 11:31:55.027545+00:00 INFO: Saved artifact /home/yura/Desktop/repos/tg/temp/training_results/_20220629_133154_e9070dfa1b63456abe3cce462444eec4/runs/0/training_task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-29 11:31:55.028901+00:00 INFO: Saved artifact /home/yura/Desktop/repos/tg/temp/training_results/_20220629_133154_e9070dfa1b63456abe3cce462444eec4/runs/0/train_split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-29 11:31:55.029638+00:00 INFO: Saved artifact /home/yura/Desktop/repos/tg/temp/training_results/_20220629_133154_e9070dfa1b63456abe3cce462444eec4/runs/0/test_splits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-29 11:31:55.030052+00:00 INFO: Completed stage 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-29 11:31:55.031555+00:00 INFO: ###METRIC###roc_auc_score_test:0.8538095238095237###\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-29 11:31:55.031966+00:00 INFO: ###METRIC###roc_auc_score_train:0.8600247283139194###\n"
     ]
    }
   ],
   "source": [
    "attached_task_id = routine.attached.execute(task,'titanic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5825ff",
   "metadata": {},
   "source": [
    "Unlike `SSHDockerRoutine`, `SagemakerTrainingRoutine` has the output, and `local` and `attached` accessors try to emulate `Sagemaker` behaviour in how the output is handled. They store the output in `Loc.temp` folder, and `execute` method returns a task id to access the result. Let's browse the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41335dd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T11:31:55.038295Z",
     "iopub.status.busy": "2022-06-29T11:31:55.037908Z",
     "iopub.status.idle": "2022-06-29T11:31:55.045374Z",
     "shell.execute_reply": "2022-06-29T11:31:55.044691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs\n",
      "runs/0\n",
      "runs/0/metrics.pkl\n",
      "runs/0/info.pkl\n",
      "runs/0/train_split.pkl\n",
      "runs/0/result_df.parquet\n",
      "runs/0/test_splits.pkl\n",
      "runs/0/model.pkl\n",
      "runs/0/training_task.pkl\n"
     ]
    }
   ],
   "source": [
    "from yo_fluq_ds import Query, FileIO\n",
    "\n",
    "attached_folder = Loc.temp_path/'training_results'/attached_task_id\n",
    "Query.folder(attached_folder, '**/*').foreach(lambda z: print(z.relative_to(attached_folder)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaa8baa",
   "metadata": {},
   "source": [
    "We can view the resulting dataframe, and compute, for instance, ROC AUC optimat threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25edc0d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T11:31:55.054455Z",
     "iopub.status.busy": "2022-06-29T11:31:55.053709Z",
     "iopub.status.idle": "2022-06-29T11:31:55.061063Z",
     "shell.execute_reply": "2022-06-29T11:31:55.060714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3483943081626346"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tg.common.ml.miscellaneous import roc_optimal_threshold\n",
    "\n",
    "df = pd.read_parquet(attached_folder/'runs/0/result_df.parquet')\n",
    "roc_optimal_threshold(df.true, df.predicted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54da2dc4",
   "metadata": {},
   "source": [
    "We can also unpickle model or the whole training task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a33ecb6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T11:31:55.067062Z",
     "iopub.status.busy": "2022-06-29T11:31:55.065822Z",
     "iopub.status.idle": "2022-06-29T11:31:55.069198Z",
     "shell.execute_reply": "2022-06-29T11:31:55.069794Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tg.common.ml.single_frame_training.training_task.SingleFrameTrainingTask at 0x7f5e204cf610>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileIO.read_pickle(attached_folder/'runs/0/training_task.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7bc2dd",
   "metadata": {},
   "source": [
    "## `local` accesor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1495d3",
   "metadata": {},
   "source": [
    "Now, let's run the task in `local` mode, i.e. inside the docker container, but on the local machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5c3c235",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T11:31:55.073946Z",
     "iopub.status.busy": "2022-06-29T11:31:55.073109Z",
     "iopub.status.idle": "2022-06-29T11:32:13.485349Z",
     "shell.execute_reply": "2022-06-29T11:32:13.484948Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "local_task_id = routine.local.execute(task,'titanic')\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5aa908",
   "metadata": {},
   "source": [
    "The output from `local` training is even closer to the real Sagemaker output: the model is packaged in `.tar.gz` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b989892",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T11:32:13.493294Z",
     "iopub.status.busy": "2022-06-29T11:32:13.492565Z",
     "iopub.status.idle": "2022-06-29T11:32:13.495197Z",
     "shell.execute_reply": "2022-06-29T11:32:13.495822Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_20220629_133155_f54f9a6473c1400ea7a0d7976dd5e989'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_task_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f939a946",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T11:32:13.500589Z",
     "iopub.status.busy": "2022-06-29T11:32:13.499710Z",
     "iopub.status.idle": "2022-06-29T11:32:13.502480Z",
     "shell.execute_reply": "2022-06-29T11:32:13.503103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.tar.gz\n",
      "output.tar.gz\n"
     ]
    }
   ],
   "source": [
    "local_path = Loc.temp_path/'training_results'/local_task_id\n",
    "Query.folder(local_path).foreach(lambda z: print(z.relative_to(local_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c44ba40",
   "metadata": {},
   "source": [
    "We have `open_sagemaker_result` method that will extract files from the archive and return `ResultPickleReader` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da4c8b8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T11:32:13.506970Z",
     "iopub.status.busy": "2022-06-29T11:32:13.506487Z",
     "iopub.status.idle": "2022-06-29T11:32:13.528705Z",
     "shell.execute_reply": "2022-06-29T11:32:13.529326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package.tag.gz\n",
      "task.json\n",
      "package.json\n",
      "hyperparameters.json\n",
      "runs/\n",
      "runs/0/\n",
      "runs/0/info.pkl\n",
      "runs/0/metrics.pkl\n",
      "runs/0/model.pkl\n",
      "runs/0/result_df.parquet\n",
      "runs/0/test_splits.pkl\n",
      "runs/0/train_split.pkl\n",
      "runs/0/training_task.pkl\n"
     ]
    }
   ],
   "source": [
    "from tg.common.delivery.training import open_sagemaker_result\n",
    "\n",
    "reader = open_sagemaker_result(local_path/'model.tar.gz', local_task_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc53be9",
   "metadata": {},
   "source": [
    "From this `reader`, we can get the paths to the files and open them directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e1909c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T11:32:13.539097Z",
     "iopub.status.busy": "2022-06-29T11:32:13.538104Z",
     "iopub.status.idle": "2022-06-29T11:32:13.550832Z",
     "shell.execute_reply": "2022-06-29T11:32:13.549926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3483943081626341"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(reader.get_path('runs/0/result_df.parquet'))\n",
    "roc_optimal_threshold(df.true, df.predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3dee01",
   "metadata": {},
   "source": [
    "However, we cannot just open the `training_task`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92941433",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T11:32:13.555561Z",
     "iopub.status.busy": "2022-06-29T11:32:13.554713Z",
     "iopub.status.idle": "2022-06-29T11:32:13.558083Z",
     "shell.execute_reply": "2022-06-29T11:32:13.557677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12644/225246354.py\", line 3, in <module>\n",
      "    FileIO.read_pickle(reader.get_path('runs/0/training_task.pkl'))\n",
      "  File \"/home/yura/anaconda3/envs/tg/lib/python3.8/site-packages/yo_fluq_ds/_misc/io.py\", line 17, in read_pickle\n",
      "    return pickle.load(file)\n",
      "ModuleNotFoundError: No module named 'titanic___20220629_133155_f54f9a6473c1400ea7a0d7976dd5e989'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "try:\n",
    "    FileIO.read_pickle(reader.get_path('runs/0/training_task.pkl'))\n",
    "except:\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf91c5c",
   "metadata": {},
   "source": [
    "Why? Because when delivering, we run all the packaging procedures, and those include creating a Training Grounds package with a unique id, and translating all the classes into this package. This package is available in the Docker container, but is not available in the python environment of the notebook where we're trying to read the results. Consequently, the reading fails.\n",
    "\n",
    "Fortunately, `ResultPickleReader` contains a method that translates everything back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e221b311",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T11:32:13.563064Z",
     "iopub.status.busy": "2022-06-29T11:32:13.562277Z",
     "iopub.status.idle": "2022-06-29T11:32:13.566542Z",
     "shell.execute_reply": "2022-06-29T11:32:13.565890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tg.common.ml.single_frame_training.training_task.SingleFrameTrainingTask"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = reader.unpickle('runs/0/training_task.pkl')\n",
    "type(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248b3dd1",
   "metadata": {},
   "source": [
    "## Notes on `remote` accesor\n",
    "\n",
    "In general, `remote` accesor performs the same way as `local`, but there are several important differences:\n",
    "* `execute` has `wait` method. When set to `False`, it will trigger the process on Sagemaker servers and exits `execute` method immediately after the process has started, without waiting for it to end. This will allow you to run several tasks. If you choose to leave `wait` to `True`, you can terminate the process on your machine once the remote training has started, it will not affect the training at `Sagemaker` servers.\n",
    "* instead of `open_sagemaker_result`, you may use `download_and_open_sagemaker_result`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9697ef",
   "metadata": {},
   "source": [
    "## Automatic task name's assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96ddf09",
   "metadata": {},
   "source": [
    "When multiple tasks are running, it's quite handy to assign to each a name that would represent the parameters of the task. Out initial idea was to implement this logic inside the task, but the downside of this approach is that parameters are many, while length of the task's name in Sagemaker is limited, and quickly reached. \n",
    "\n",
    "The alternative solution is to, first, use a factory method that builds tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "622efe53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T11:32:13.572550Z",
     "iopub.status.busy": "2022-06-29T11:32:13.571436Z",
     "iopub.status.idle": "2022-06-29T11:32:13.573939Z",
     "shell.execute_reply": "2022-06-29T11:32:13.573322Z"
    }
   },
   "outputs": [],
   "source": [
    "from yo_fluq_ds import Obj\n",
    "\n",
    "def build(\n",
    "    learning_rate=1, \n",
    "    network_size=[10,10], \n",
    "    context_length = 10,\n",
    "):\n",
    "    return Obj(info=dict(name=''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e2f019",
   "metadata": {},
   "source": [
    "This `build` method returns a mock for training task: we are now interested only in `info` field of the task, that will contain the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b034f7f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T11:32:13.579175Z",
     "iopub.status.busy": "2022-06-29T11:32:13.578602Z",
     "iopub.status.idle": "2022-06-29T11:32:13.581264Z",
     "shell.execute_reply": "2022-06-29T11:32:13.581671Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'info': {'name': 'LR1-NS10'}},\n",
       " {'info': {'name': 'LR1-NS10-5'}},\n",
       " {'info': {'name': 'LR2-NS10'}},\n",
       " {'info': {'name': 'LR2-NS10-5'}}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tg.common.delivery.training import Autonamer\n",
    "\n",
    "Autonamer(build).build_tasks(learning_rate = [1, 2], network_size = [[10], [10, 5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e5fb33",
   "metadata": {},
   "source": [
    "As we can see, `Autonamer` will instantiate all the tasks and assign automatically generated names to them. Note that it does not create entry for `context_length` in the name, as it is not variable in this run. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
