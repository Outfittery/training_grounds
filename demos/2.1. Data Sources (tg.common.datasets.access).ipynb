{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1. Data Sources (tg.common.datasets.access)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Training Ground offers the Data Objects Flow (DOF) model as the primary interface to access the data: \n",
    "\n",
    "* *Data object* are non-relational JSONs, typically huge and containing nested lists and dictionaries. \n",
    "* *Flow* means that objects are not placed in memory all at once, but are accessible as a python iterator.\n",
    "\n",
    "`DataSource` is the primary interface that hides the database implementation and exposes data in DOF format: `get_data` method returns an interator, wrapped as `Queryable` class from `yo_fluq_ds` (https://pypi.org/project/yo-fluq-ds/). `DataSource` is a necessary abstraction that hides the details of how the data are actually stored: be it relational database, AWS S3 storage or simply a file, as long as the data can be represented as a flow of DOFs, you will be able to use it in your project. If the data storage changes, you may adapt to this change by replacing the `DataSource` implementation and keeping the rest of the featurization process intact. Typically, you need to implement your own `DataSource` inheritants for the storages you have in your environment.\n",
    "\n",
    "The goal of featurization is typically converting DOF into a tidy dataframe. In this demo, we will work with the well-known Titanic dataset, which is stored in the local folder as a `csv` file. Of course, it already contains all the data in the tidy format, but for the sake of the demonstration we will distort this format. In the following demos, the tidiness will be restored again with the TG-pipeline. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSource \n",
    "\n",
    "\n",
    "The first step is to write your own `DataSource` class, that will make Titanic dataset available as DOF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T12:03:30.775313Z",
     "start_time": "2021-04-01T12:03:30.048707Z"
    },
    "execution": {
     "iopub.execute_input": "2022-08-09T09:25:51.753605Z",
     "iopub.status.busy": "2022-08-09T09:25:51.753083Z",
     "iopub.status.idle": "2022-08-09T09:25:52.704159Z",
     "shell.execute_reply": "2022-08-09T09:25:52.704643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1, 'ticket': {'ticket.id': 'A/5 21171', 'fare': 7.25, 'Pclass': 3}, 'passenger': {'Name': 'Braund, Mr. Owen Harris', 'Sex': 'male', 'Age': 22.0}, 'trip': {'Survived': 0, 'SibSp': 1, 'Patch': 0, 'Cabin': nan, 'Embarked': 'S'}}\n"
     ]
    }
   ],
   "source": [
    "from yo_fluq_ds import Query, Queryable\n",
    "from tg.common.datasets.access import DataSource\n",
    "import pandas as pd\n",
    "\n",
    "class CsvDataSource(DataSource):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "\n",
    "    def _get_data_iter(self):\n",
    "        df = pd.read_csv(self.filename)\n",
    "        for row in df.iterrows():\n",
    "            d = row[1].to_dict()\n",
    "            yield  {\n",
    "                'id': d['PassengerId'],\n",
    "                'ticket': {\n",
    "                    'ticket.id': d['Ticket'],\n",
    "                    'fare': d['Fare'],\n",
    "                    'Pclass': d['Pclass']\n",
    "                },\n",
    "                'passenger': {\n",
    "                    'Name': d['Name'],\n",
    "                    'Sex': d['Sex'],\n",
    "                    'Age': d['Age']\n",
    "                },\n",
    "                'trip': {\n",
    "                    'Survived': d['Survived'],\n",
    "                    'SibSp': d['SibSp'],\n",
    "                    'Patch': d['Parch'],\n",
    "                    'Cabin': d['Cabin'],\n",
    "                    'Embarked' : d['Embarked']\n",
    "                    \n",
    "                }\n",
    "            }\n",
    "            \n",
    "    def get_data(self) -> Queryable:\n",
    "        return Query.en(self._get_data_iter())\n",
    "    \n",
    "source = CsvDataSource('titanic.csv')\n",
    "\n",
    "for row in source.get_data():\n",
    "    print(row)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `_get_data_iter` creates an iterator, that yields objects one after another. In `get_data`, we simply wrap this iterator in `Queryable` type from `yo_fluq`. It's still the iterator, so we can iterate over it, as `for` loop demonstrates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Queryable` class contains a variety of methods for easy-to-write data processing, which are the Python-port of LINQ technology in C#. The methods are explained in full details in https://pypi.org/project/yo-fluq-ds/ . The access to the DOF in `Queryable` format allows you to quickly perform exploratory data analysis. As an example, consider the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T12:03:43.587888Z",
     "start_time": "2021-04-01T12:03:43.509947Z"
    },
    "execution": {
     "iopub.execute_input": "2022-08-09T09:25:52.713920Z",
     "iopub.status.busy": "2022-08-09T09:25:52.712384Z",
     "iopub.status.idle": "2022-08-09T09:25:52.802107Z",
     "shell.execute_reply": "2022-08-09T09:25:52.802410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket.id</th>\n",
       "      <th>fare</th>\n",
       "      <th>Pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2625</td>\n",
       "      <td>8.5167</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250649</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>248738</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticket.id     fare  Pclass\n",
       "0      2625   8.5167       3\n",
       "1    250649  14.5000       2\n",
       "2    248738  29.0000       2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(source\n",
    " .get_data()\n",
    " .where(lambda z: z['passenger']['Sex']=='male')\n",
    " .order_by(lambda z: z['passenger']['Age'])\n",
    " .select(lambda z: z['ticket'])\n",
    " .take(3)\n",
    " .to_dataframe()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The meaning is self-evident: filter by `Sex`, order by `Age` and select the `Ticket` information out of the records, then take 3 of them in the format of pandas `DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite often we want to make the data available offline, so the data is available faster and do not create a load on the external server. The typical use cases are:\n",
    "\n",
    "* Exploratory data analysis\n",
    "* Functional tests in your service: these tests often use the real data, and it's impractical to wait each time for this data to be delivered.\n",
    "* Debugging of you services: most of the data services are downloading some data at the beginning, and in order to speed-up the startup when debugging on the local machine, it's helpful to create a cache.\n",
    "\n",
    "To make data source cacheable, create a wrapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T12:03:43.591404Z",
     "start_time": "2021-04-01T12:03:43.589121Z"
    },
    "execution": {
     "iopub.execute_input": "2022-08-09T09:25:52.806702Z",
     "iopub.status.busy": "2022-08-09T09:25:52.804537Z",
     "iopub.status.idle": "2022-08-09T09:25:52.811115Z",
     "shell.execute_reply": "2022-08-09T09:25:52.810321Z"
    }
   },
   "outputs": [],
   "source": [
    "from tg.common.datasets.access import ZippedFileDataSource, CacheableDataSource\n",
    "\n",
    "cacheable_source = CacheableDataSource(\n",
    "    inner_data_source = source,\n",
    "    file_data_source = ZippedFileDataSource(path='./temp/source/titanic')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CacheableDataSource` is still a `DataSource` and can be called directly. In this case, the original source will be called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T12:03:43.604077Z",
     "start_time": "2021-04-01T12:03:43.592572Z"
    },
    "execution": {
     "iopub.execute_input": "2022-08-09T09:25:52.816232Z",
     "iopub.status.busy": "2022-08-09T09:25:52.815767Z",
     "iopub.status.idle": "2022-08-09T09:25:52.914570Z",
     "shell.execute_reply": "2022-08-09T09:25:52.914008Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'ticket': {'ticket.id': 'A/5 21171', 'fare': 7.25, 'Pclass': 3},\n",
       " 'passenger': {'Name': 'Braund, Mr. Owen Harris', 'Sex': 'male', 'Age': 22.0},\n",
       " 'trip': {'Survived': 0,\n",
       "  'SibSp': 1,\n",
       "  'Patch': 0,\n",
       "  'Cabin': nan,\n",
       "  'Embarked': 'S'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cacheable_source.get_data().first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we can also access data this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T12:03:43.612630Z",
     "start_time": "2021-04-01T12:03:43.605227Z"
    },
    "execution": {
     "iopub.execute_input": "2022-08-09T09:25:52.921482Z",
     "iopub.status.busy": "2022-08-09T09:25:52.918281Z",
     "iopub.status.idle": "2022-08-09T09:25:52.925698Z",
     "shell.execute_reply": "2022-08-09T09:25:52.926302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'ticket': {'ticket.id': 'A/5 21171', 'fare': 7.25, 'Pclass': 3},\n",
       " 'passenger': {'Name': 'Braund, Mr. Owen Harris', 'Sex': 'male', 'Age': 22.0},\n",
       " 'trip': {'Survived': 0,\n",
       "  'SibSp': 1,\n",
       "  'Patch': 0,\n",
       "  'Cabin': nan,\n",
       "  'Embarked': 'S'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tg.common.datasets.access import CacheMode\n",
    "\n",
    "cacheable_source.safe_cache(CacheMode.Default).get_data().first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use a string constant for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T09:25:52.933860Z",
     "iopub.status.busy": "2022-08-09T09:25:52.933387Z",
     "iopub.status.idle": "2022-08-09T09:25:52.941075Z",
     "shell.execute_reply": "2022-08-09T09:25:52.941805Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'ticket': {'ticket.id': 'A/5 21171', 'fare': 7.25, 'Pclass': 3},\n",
       " 'passenger': {'Name': 'Braund, Mr. Owen Harris', 'Sex': 'male', 'Age': 22.0},\n",
       " 'trip': {'Survived': 0,\n",
       "  'SibSp': 1,\n",
       "  'Patch': 0,\n",
       "  'Cabin': nan,\n",
       "  'Embarked': 'S'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cacheable_source.safe_cache('default').get_data().first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`safe_cache` accepts the following modes: \n",
    "* `CacheMode.Default/default` mode, in this case `safe_cache` will create the cache in the `path` folder, provided to `ZippedFileDataSource`, if it does not exists, and read from it. \n",
    "* `CacheMode.Use/use` mode. the error will be thrown if cache does not exist locally. \n",
    "* `CacheMode.No/no` mode, the underlying source will be called directly, the cache will neither created nor used.\n",
    "* `CacheMode.Remake/remake` forces the cache to be created even if it already exists.\n",
    "\n",
    "So, when developing, we can use caches to save time, but when deploying, disable caching them with simple change of the argument. \n",
    "\n",
    "The format for the created cache file is a zipped folder with files that contains pickled data separated into bins. Normally, you don't need to intervene to their size. Increasing the bins size increases both performance and memory consumption. Theoretically, you may use another format by implementing your own class instead of `ZippedFileDataSource`. However, it's only recommended: the current format is a result of a comparative research, and other, more obvious ways of caching (caching everything in one file, or caching each object in an invidual file) perform much slower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional use of `CacheMode`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, `CacheMode` often becomes a single argument to the whole data aquisition component of the application: \n",
    "* `no` is used for the production run\n",
    "* `default` for local debugging, this way all the nesessary data is cached and starting the application up is much faster\n",
    "* `remake` if you want to update the local data\n",
    "* `use` in integration tests, which you want to run quickly and exactly on the same data the local application is running\n",
    "\n",
    "Since data aquisition may sometimes go without `DataSource` class, the following method is created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T09:25:52.948088Z",
     "iopub.status.busy": "2022-08-09T09:25:52.947293Z",
     "iopub.status.idle": "2022-08-09T09:25:52.951594Z",
     "shell.execute_reply": "2022-08-09T09:25:52.951988Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('92cd4fb0-7d6f-4633-8bdb-b8976cb0cff8',\n",
       " '92cd4fb0-7d6f-4633-8bdb-b8976cb0cff8',\n",
       " '5ee75250-6fcf-4772-b52e-d5046cfba58e')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "def create_data():\n",
    "    return str(uuid4())\n",
    "\n",
    "uid1 = CacheMode.apply_to_file(\n",
    "    CacheMode.Default,\n",
    "    './temp/cached_data',\n",
    "    create_data\n",
    ")\n",
    "\n",
    "uid2 = CacheMode.apply_to_file(\n",
    "    CacheMode.Default,\n",
    "    './temp/cached_data',\n",
    "    create_data\n",
    ")\n",
    "\n",
    "uid3 = CacheMode.apply_to_file(\n",
    "    CacheMode.No,\n",
    "    './temp/cached_data',\n",
    "    create_data\n",
    ")\n",
    "\n",
    "uid1, uid2, uid3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First time dataframe will be created by `create_data` method, but for the second time, it will be read from the file, so `uid1` and `uid2` are the same, `uid3` is different, because `CacheMode.No` was used as an argument.\n",
    "\n",
    "In the particular case of data in `pandas` dataframe format, TG also offers `DataFrameSource` interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T09:25:52.963237Z",
     "iopub.status.busy": "2022-08-09T09:25:52.962455Z",
     "iopub.status.idle": "2022-08-09T09:25:52.966638Z",
     "shell.execute_reply": "2022-08-09T09:25:52.967039Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b\n",
       "0  1  2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tg.common.datasets.access import DataFrameSource\n",
    "\n",
    "class TestDataFrameSource(DataFrameSource):\n",
    "    def get_df(self):\n",
    "        return pd.DataFrame([dict(a=1,b=2)])\n",
    "    \n",
    "src = TestDataFrameSource()\n",
    "src.get_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_cached_df` method wraps `CacheMode.apply_to_file` method and allows you to cache dataframe quicker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this demo, we have covered the following topics:\n",
    "* Data Objects Flow as the primary model of incoming data in TG fearurization process\n",
    "* `DataSource` as the main interface providing DOF\n",
    "* Caching `DataSource` with `CacheableDataSource` and `CacheMode`\n",
    "* Caching other types of data\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
